{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import sys\n",
    "import xlwt\n",
    "import MySQLdb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def transfromData(trainRaw, testRaw,windosSize):  ##Train ratial, train, test\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    #npRaw = np.array(rawData)\n",
    "    #scaledData = sc.fit_transform(npRaw.reshape(-1,1))  \n",
    "    #trainData = np.array(scaledData[:trainCount]).reshape(-1,1)##train \n",
    "    #testData = np.array(scaledData[-testCount:]).reshape(-1,1)\n",
    "    \n",
    "    npTrain = sc.fit_transform(np.array(trainRaw).reshape(-1,1))\n",
    "    npTest = sc.fit_transform(np.array(testRaw).reshape(-1,1))\n",
    "    \n",
    "\n",
    "    X_train, y_train = splitXy(npTrain,windosSize)\n",
    "    X_test, y_test = splitXy(npTest,windosSize)\n",
    "    return sc, X_train, y_train, X_test, y_test\n",
    "\n",
    "def splitXy(data,windosSize):\n",
    "    windows = []\n",
    "    for i in range(windosSize, data.shape[0]):\n",
    "        windows.append(data[i-windosSize:i, 0])\n",
    "    np.random.shuffle(windows)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(windows)):\n",
    "        X.append(windows[i][:6])\n",
    "        y.append(windows[i][-(windosSize-6):])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    return X,y\n",
    "def buildModel(outSize):\n",
    "    regressor = Sequential()\n",
    "    #regressor.add(Bidirectional(LSTM(units=50,return_sequences=True),input_shape = (X_train.shape[1], 1)))\n",
    "    regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(LSTM(units = 50,return_sequences=True))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(LSTM(units = 50))\n",
    "    regressor.add(Dropout(0.2))\n",
    "    regressor.add(Dense(units = outSize))\n",
    "    # Compiling\n",
    "    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    return regressor\n",
    "def getStationList(cursor):\n",
    "    stationList = []\n",
    "    queryString = \"SELECT distinct station from cleandata\"\n",
    "    cursor.execute(queryString)\n",
    "    results = cursor.fetchall()\n",
    "    for row in results :\n",
    "        val = str(row).strip(\"',()\")\n",
    "        stationList.append(val)\n",
    "    stationList.remove('富貴角')##only 106少數資料\n",
    "    return stationList\n",
    "def Visualize():\n",
    "    predicted = sc.inverse_transform(regressor.predict(X_test))\n",
    "    originY = sc.inverse_transform (y_test)\n",
    "    print(\"MSE : [\"+str(mean_squared_error(predicted, originY))+\"]\")\n",
    "    # Visualising the results\n",
    "    plt.plot(originY[:100], color = 'red', label = 'Real')  \n",
    "    plt.plot(predicted[:100], color = 'blue', label = 'Predicted ') \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def writeExcelHead(sheet1,epochs,station):\n",
    "    sheet1.write(0,1,station)\n",
    "    raw = 1\n",
    "    for e in range(epochs):\n",
    "        sheet1.write(raw,0,e+1)\n",
    "        raw+=1\n",
    "\n",
    "##get data##\n",
    "\n",
    "def fetchData(cursor,station,windosSize):\n",
    "    queryString = \"SELECT * from cleandata where station='\"+station+\"' and item = 'PM2.5' and date NOT like '2017%'\"\n",
    "    cursor.execute(queryString)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    trainRawData = []\n",
    "    for row in results:\n",
    "        for i in range(3,27):\n",
    "            trainRawData.append(float(row[i]))\n",
    "            \n",
    "    queryString = \"SELECT * from cleandata where station='\"+station+\"' and item = 'PM2.5' and date like '2017%'\"\n",
    "    cursor.execute(queryString)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    testRawData = []\n",
    "    for row in results:\n",
    "        for i in range(3,27):\n",
    "            testRawData.append(float(row[i]))\n",
    "\n",
    "    sc, X_train, y_train, X_test, y_test = transfromData(trainRawData,testRawData,windosSize)\n",
    "    return sc, X_train, y_train, X_test, y_test\n",
    "def train(regressor,sc, X_train, y_train, X_test, y_test,epochs):\n",
    "    for i in range(epochs):\n",
    "        regressor.fit(X_train, y_train,validation_split=0.2, epochs = 1, batch_size = 32,verbose=2)\n",
    "        predicted = sc.inverse_transform(regressor.predict(X_test))\n",
    "        originY = sc.inverse_transform (y_test)\n",
    "        mse = mean_squared_error(predicted, originY)\n",
    "        print(\"Epoch : \" +str(i)+\", MSE : [\"+str(mse)+\"]\")\n",
    "        print('-------------------------------------------')\n",
    "  \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training : 二林\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch : 0, MSE : [67.121008035305]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0014 - val_loss: 8.3441e-04\n",
      "Epoch : 1, MSE : [26.209321933794012]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 9.7915e-04 - val_loss: 8.0966e-04\n",
      "Epoch : 2, MSE : [27.376134165018936]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.3589e-04 - val_loss: 7.2826e-04\n",
      "Epoch : 3, MSE : [26.23450853296214]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.8177e-04 - val_loss: 7.5140e-04\n",
      "Epoch : 4, MSE : [27.13823305316961]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.7556e-04 - val_loss: 7.1433e-04\n",
      "Epoch : 5, MSE : [25.359126339867675]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.8706e-04 - val_loss: 7.6239e-04\n",
      "Epoch : 6, MSE : [28.224715566725042]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.7526e-04 - val_loss: 7.7580e-04\n",
      "Epoch : 7, MSE : [27.71793711890194]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.8207e-04 - val_loss: 7.1202e-04\n",
      "Epoch : 8, MSE : [25.415236952270156]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.6733e-04 - val_loss: 7.1092e-04\n",
      "Epoch : 9, MSE : [24.908908053843046]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.5039e-04 - val_loss: 7.2556e-04\n",
      "Epoch : 10, MSE : [26.24564049121382]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2571e-04 - val_loss: 6.9138e-04\n",
      "Epoch : 11, MSE : [24.830896666435375]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.3190e-04 - val_loss: 7.0028e-04\n",
      "Epoch : 12, MSE : [24.729947963051938]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.5360e-04 - val_loss: 7.0098e-04\n",
      "Epoch : 13, MSE : [24.334813618655268]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.4236e-04 - val_loss: 7.0829e-04\n",
      "Epoch : 14, MSE : [24.841603056065086]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2255e-04 - val_loss: 7.7800e-04\n",
      "Epoch : 15, MSE : [25.435165205260468]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2745e-04 - val_loss: 6.8604e-04\n",
      "Epoch : 16, MSE : [25.302143529865546]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.3515e-04 - val_loss: 6.8490e-04\n",
      "Epoch : 17, MSE : [24.713388983652383]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2220e-04 - val_loss: 7.0460e-04\n",
      "Epoch : 18, MSE : [24.749309488857715]\n",
      "-------------------------------------------\n",
      "Train on 17140 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2462e-04 - val_loss: 7.3738e-04\n",
      "Epoch : 19, MSE : [27.211559314870758]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 7s - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch : 0, MSE : [63.37733426707399]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch : 1, MSE : [42.82674412468877]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch : 2, MSE : [40.50695706944441]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch : 3, MSE : [39.077003368023284]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch : 4, MSE : [40.39684832004658]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch : 5, MSE : [39.41724560040693]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch : 6, MSE : [39.56859436493956]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch : 7, MSE : [38.69080255213238]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch : 8, MSE : [44.55675931842737]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch : 9, MSE : [38.19105925714431]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 10, MSE : [38.66050147695036]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 11, MSE : [37.807355851518636]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 12, MSE : [38.615696735821025]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 13, MSE : [38.881033689208444]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 14, MSE : [39.46606318047692]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 15, MSE : [39.35270743317933]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 16, MSE : [40.23560655878491]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 17, MSE : [37.742734518631245]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 18, MSE : [38.35484219964664]\n",
      "-------------------------------------------\n",
      "Train on 17139 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch : 19, MSE : [39.69808131643997]\n",
      "-------------------------------------------\n",
      "Train on 17138 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 7s - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch : 0, MSE : [75.72745600008709]\n",
      "-------------------------------------------\n",
      "Train on 17138 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch : 1, MSE : [56.46230561759162]\n",
      "-------------------------------------------\n",
      "Train on 17138 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch : 2, MSE : [53.40669270451747]\n",
      "-------------------------------------------\n",
      "Train on 17138 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch : 3, MSE : [53.93275439099344]\n",
      "-------------------------------------------\n",
      "Train on 17138 samples, validate on 4285 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0019 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, MSE : [54.43269219167098]\n",
      "-------------------------------------------\n",
      "Train on 17138 samples, validate on 4285 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8c194c47f01b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetchData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mregressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuildModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mMSEs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-648496665a59>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(regressor, sc, X_train, y_train, X_test, y_test, epochs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0moriginY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ming\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\ming\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ming\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ming\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ming\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "db=MySQLdb.connect(host=\"localhost\",user=\"root\", passwd=\"swater0\", db=\"airdb\", charset=\"utf8\")\n",
    "cursor = db.cursor()\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "stationList = getStationList(cursor)\n",
    "\n",
    "col=1\n",
    "for station in stationList:\n",
    "    print(\"training : \" +station)\n",
    "    MSEs = []\n",
    "    for windowSize in range(7,17):\n",
    "        sc, X_train, y_train, X_test, y_test = fetchData(cursor,station,windowSize)\n",
    "        regressor = buildModel(windowSize-6)\n",
    "        mse = train(regressor,sc,X_train, y_train, X_test, y_test,epochs)\n",
    "        MSEs.append(mse)\n",
    "        \n",
    "    book = xlwt.Workbook(encoding=\"utf-8\")\n",
    "    sheet1 = book.add_sheet(\"Sheet1\")\n",
    "    writeExcelHead(sheet1,epochs,station)\n",
    "    row = 1\n",
    "    for m in MSEs:\n",
    "        sheet1.write(row,1,m)\n",
    "        row+=1\n",
    "    book.save(\"excelFiles/LSTM/LSTMresult\"+station+\".xls\")\n",
    "        \n",
    "    print('check point at ' + str(datetime.datetime.now()))\n",
    "\n",
    "db.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "book.save(\"Test1EXCCCC.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
